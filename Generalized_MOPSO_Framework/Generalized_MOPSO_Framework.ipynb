{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda06395-8d6d-4150-8f48-63f7c7a28eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# IMPORTS\n",
    "# - numpy, pandas: numerical + data handling\n",
    "# - pyswarm: PSO implementation\n",
    "# - sklearn: scaling data\n",
    "# - tensorflow: for loading DNN models\n",
    "# - joblib: saving/loading preprocessing objects\n",
    "# - matplotlib: plotting convergence results\n",
    "# - os/json/typing: file ops, configs, type hints\n",
    "################################################################\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyswarm import pso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from typing import List, Dict, Union, Tuple, Any\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    message=\"X does not have valid feature names, but StandardScaler was fitted with feature names\",\n",
    "    category=UserWarning,\n",
    "    module=\"sklearn\"\n",
    ")\n",
    "\n",
    "################################################################\n",
    "# CLASS: GeneralizedMOPSO\n",
    "# - Implements a generalized Multi-Objective Particle Swarm Optimization\n",
    "# - Handles multiple models (objectives), scalers, bounds, constraints\n",
    "# - Tracks optimization history for analysis\n",
    "# - Includes early termination based on convergence criteria\n",
    "################################################################\n",
    "\n",
    "class GeneralizedMOPSO:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor initializes storage dictionaries, \n",
    "        PSO variables, and optimization tracking history.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Store ML models and scalers for each objective\n",
    "        self.models = {}\n",
    "        self.scalers_X = {}\n",
    "        self.scalers_y = {}\n",
    "        \n",
    "        # Parameter + objective configurations\n",
    "        self.parameter_info = {}\n",
    "        self.objective_targets = {}\n",
    "        self.objective_constraints = {}\n",
    "        self.bounds = {}\n",
    "        self.discrete_mappings = {}\n",
    "        \n",
    "        # PSO optimization tracking\n",
    "        self.best_solutions_history = [] # best parameters at each iteration\n",
    "        self.best_values_history = []    # best objective values\n",
    "        self.actual_value_history = []   # unscaled objective values\n",
    "        self.objective_histories = {}    # per-objective performance\n",
    "        self.constraint_penalty_history = []\n",
    "        self.constraint_violation_history = []\n",
    "        self.particle_trajectories = []\n",
    "        \n",
    "        # PSO parameters\n",
    "        self.velocity = None\n",
    "        self.best_global_position = None\n",
    "        self.best_global_value = np.inf\n",
    "        self.inertia_weight = 0.5\n",
    "        \n",
    "        # Early termination parameters\n",
    "        self.convergence_threshold = 10e-6\n",
    "        self.stagnation_limit = 50\n",
    "        self.convergence_window = []\n",
    "        self.early_terminated = False\n",
    "        self.termination_reason = \"\"\n",
    "        \n",
    "    \n",
    "    \n",
    "    ################################################################\n",
    "    # ENVIRONMENT SETUP FUNCTIONS\n",
    "    ################################################################\n",
    "    \n",
    "    def setup_environment(self):\n",
    "        \"\"\"Setup the optimization environment by loading models and setting up \n",
    "        base directory, objectives, parameters, models, and constraints\"\"\"\n",
    "        \n",
    "        print(\"=== GENERALIZED MULTI-OBJECTIVE PSO OPTIMIZER ===\\n\")\n",
    "        \n",
    "        # 1. Get base path for models/scalers\n",
    "        \n",
    "        while True:\n",
    "            self.base_path = input(\"Enter the directory path for loading model and scalers: \").strip()\n",
    "            if os.path.isdir(self.base_path):   # checks instantly if directory exists\n",
    "                print(f\"\\n Valid path found: {self.base_path}\\n\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\" Path not found: {self.base_path}\")\n",
    "                print(\"Please enter a correct directory path.\\n\")\n",
    "            \n",
    "               \n",
    "        # 2. Define objectives\n",
    "        self._setup_objectives()\n",
    "        \n",
    "         # 3. Define optimization input parameters (bounds, discrete/continuous)\n",
    "        self._setup_input_parameters()\n",
    "        \n",
    "        # 4. Load ML models and scalers (IMPORTANT)\n",
    "        self._load_models_and_scalers()\n",
    "        \n",
    "        # 5. Define optimization targets (min/target) and constraints\n",
    "        self._setup_optimization_targets()\n",
    "        \n",
    "        print(\"\\n Environment setup complete!\")\n",
    "        \n",
    "    def _setup_objectives(self):\n",
    "        \"\"\"Setup optimization objectives\"\"\"\n",
    "        \"\"\"Define number and names of optimization objectives from trained DNN json file\"\"\"\n",
    "        print(\"\\n--- OPTIMIZATION OBJECTIVES SETUP ---\")\n",
    "        num_objectives = int(input(\"Enter number of objectives to optimize: \"))\n",
    "\n",
    "        print(\"Note the name of objective functions should be same as used for ANN training (See .json file)\")\n",
    "        for i in range(num_objectives):\n",
    "            obj_name = input(f\"Enter name for objective {i+1}: \").strip()\n",
    "            self.objective_targets[obj_name] = {}\n",
    "            self.objective_constraints[obj_name] = {}\n",
    "            self.objective_histories[obj_name] = []\n",
    "            \n",
    "    def _setup_input_parameters(self):\n",
    "        \"\"\"Define input parameters (continuous bounds or discrete set)\"\"\"\n",
    "        \n",
    "        print(\"\\n--- INPUT PARAMETERS SETUP ---\")\n",
    "        num_params = int(input(\"Enter number of input parameters: \"))\n",
    "        print(\"Note the name of input prameters should be same as used for ANN training (See .json file)\")\n",
    "        for i in range(num_params):\n",
    "            param_name = input(f\"\\nEnter name for parameter {i+1}: \").strip()\n",
    "            \n",
    "            # Check if continuous or discrete\n",
    "            is_continuous = input(f\"Is '{param_name}' continuous? (y/n): \").strip().lower() == 'y'\n",
    "            \n",
    "            if is_continuous:\n",
    "                lower = float(input(f\"Enter lower bound for {param_name}: \"))\n",
    "                upper = float(input(f\"Enter upper bound for {param_name}: \"))\n",
    "                self.parameter_info[param_name] = {\n",
    "                    'type': 'continuous',\n",
    "                    'bounds': (lower, upper)\n",
    "                }\n",
    "                self.bounds[param_name] = (lower, upper)\n",
    "            else:\n",
    "                print(f\"Enter discrete values for {param_name} (comma-separated):\")\n",
    "                discrete_vals_input = input().strip()\n",
    "                \n",
    "                # Try to parse as numbers first, then as strings\n",
    "                try:\n",
    "                    discrete_vals = [float(x.strip()) for x in discrete_vals_input.split(',')]\n",
    "                except ValueError:\n",
    "                    discrete_vals = [x.strip() for x in discrete_vals_input.split(',')]\n",
    "                \n",
    "                self.parameter_info[param_name] = {\n",
    "                    'type': 'discrete',\n",
    "                    'values': discrete_vals\n",
    "                }\n",
    "                \n",
    "                # Create mapping for discrete values\n",
    "                self.discrete_mappings[param_name] = {i: val for i, val in enumerate(discrete_vals)}\n",
    "                self.bounds[param_name] = (0, len(discrete_vals) - 1)\n",
    "                \n",
    "    def _load_models_and_scalers(self):\n",
    "        \"\"\"Load pre-trained models and their scalers from files\"\"\"\n",
    "        \n",
    "        print(\"\\n--- LOADING MODELS AND SCALERS ---\")\n",
    "        \n",
    "        def load_file_by_name(base_path, partial_name, loader_func):\n",
    "            for file in os.listdir(base_path):\n",
    "                if partial_name.lower() in file.lower():\n",
    "                    print(f\"Loading: {file}\")\n",
    "                    return loader_func(os.path.join(base_path, file))\n",
    "            raise FileNotFoundError(f\"No file found containing '{partial_name}' in {base_path}\")\n",
    "        \n",
    "        for obj_name in self.objective_targets.keys():\n",
    "            try:\n",
    "                # Load scalers\n",
    "                self.scalers_X[obj_name] = load_file_by_name(\n",
    "                    self.base_path, f\"{obj_name}_scaler_X\", joblib.load\n",
    "                )\n",
    "                self.scalers_y[obj_name] = load_file_by_name(\n",
    "                    self.base_path, f\"{obj_name}_scaler_y\", joblib.load\n",
    "                )\n",
    "                \n",
    "                # Load model\n",
    "                self.models[obj_name] = load_file_by_name(\n",
    "                    self.base_path, f\"{obj_name}_trained_model\", tf.keras.models.load_model\n",
    "                )\n",
    "                \n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Warning: {e}\")\n",
    "                print(f\"Please ensure files exist for objective '{obj_name}'\")\n",
    "                \n",
    "    def _setup_optimization_targets(self):\n",
    "        \"\"\"Setup target values, weights, and constraints for each objective\"\"\"\n",
    "        print(\"\\n--- OPTIMIZATION TARGETS & CONSTRAINTS SETUP ---\")\n",
    "        \n",
    "        for obj_name in self.objective_targets.keys():\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Setting up '{obj_name}' objective:\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Setup optimization target\n",
    "            target_type = input(\"Minimize (min) or target specific value (target)? \").strip().lower()\n",
    "            \n",
    "            if target_type == 'target':\n",
    "                target_val = float(input(f\"Enter target value for {obj_name}: \"))\n",
    "                max_val = float(input(f\"Enter maximum acceptable value for {obj_name}: \"))\n",
    "                self.objective_targets[obj_name] = {\n",
    "                    'type': 'target',\n",
    "                    'target_value': target_val,\n",
    "                    'max_value': max_val\n",
    "                }\n",
    "            else:\n",
    "                max_val = float(input(f\"Enter maximum value for normalization of {obj_name}: \"))\n",
    "                self.objective_targets[obj_name] = {\n",
    "                    'type': 'minimize',\n",
    "                    'max_value': max_val\n",
    "                }\n",
    "            \n",
    "            # Setup constraints\n",
    "            self._setup_constraints_for_objective(obj_name)\n",
    "    \n",
    "    def _setup_constraints_for_objective(self, obj_name: str):\n",
    "        \"\"\"Setup constraints for a specific objective\"\"\"\n",
    "        print(f\"\\n--- CONSTRAINTS FOR '{obj_name}' ---\")\n",
    "        \n",
    "        has_constraints = input(f\"Add constraints for {obj_name}? (y/n): \").strip().lower() == 'y'\n",
    "        \n",
    "        if not has_constraints:\n",
    "            self.objective_constraints[obj_name] = {\n",
    "                'has_constraints': False\n",
    "            }\n",
    "            return\n",
    "        \n",
    "        constraints = {\n",
    "            'has_constraints': True,\n",
    "            'min_constraint': None,\n",
    "            'max_constraint': None,\n",
    "            'penalty_weight': 1000.0  # Default high penalty weight\n",
    "        }\n",
    "        \n",
    "        # Minimum constraint\n",
    "        has_min = input(f\"Set minimum limit for {obj_name}? (y/n): \").strip().lower() == 'y'\n",
    "        if has_min:\n",
    "            min_val = float(input(f\"Enter minimum allowed value for {obj_name}: \"))\n",
    "            constraints['min_constraint'] = min_val\n",
    "            print(f\"✓ Minimum constraint set: {obj_name} >= {min_val}\")\n",
    "        \n",
    "        # Maximum constraint\n",
    "        has_max = input(f\"Set maximum limit for {obj_name}? (y/n): \").strip().lower() == 'y'\n",
    "        if has_max:\n",
    "            max_val = float(input(f\"Enter maximum allowed value for {obj_name}: \"))\n",
    "            constraints['max_constraint'] = max_val\n",
    "            print(f\"✓ Maximum constraint set: {obj_name} <= {max_val}\")\n",
    "        \n",
    "        # Penalty weight\n",
    "        custom_penalty = input(f\"Use custom penalty weight? (default: 1000) (y/n): \").strip().lower() == 'y'\n",
    "        if custom_penalty:\n",
    "            penalty = float(input(\"Enter penalty weight (higher = stricter constraint): \"))\n",
    "            constraints['penalty_weight'] = penalty\n",
    "        \n",
    "        self.objective_constraints[obj_name] = constraints\n",
    "        \n",
    "        # Print constraint summary\n",
    "        print(f\"\\n--- CONSTRAINT SUMMARY FOR '{obj_name}' ---\")\n",
    "        if constraints['min_constraint'] is not None:\n",
    "            print(f\"  Minimum: {constraints['min_constraint']}\")\n",
    "        if constraints['max_constraint'] is not None:\n",
    "            print(f\"  Maximum: {constraints['max_constraint']}\")\n",
    "        print(f\"  Penalty Weight: {constraints['penalty_weight']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "    def _check_convergence(self, current_value: float) -> bool:\n",
    "        \"\"\"\n",
    "        Check if optimization has converged based on stagnation criteria.\n",
    "        Returns True if optimization should terminate early.\n",
    "        \"\"\"\n",
    "        # Add current value to the convergence window\n",
    "        self.convergence_window.append(current_value)\n",
    "        \n",
    "        # Keep only the last 'stagnation_limit' values\n",
    "        if len(self.convergence_window) > self.stagnation_limit:\n",
    "            self.convergence_window.pop(0)\n",
    "        \n",
    "        # Check convergence only if we have enough values\n",
    "        if len(self.convergence_window) < self.stagnation_limit:\n",
    "            return False\n",
    "        \n",
    "        # Calculate the range of values in the convergence window\n",
    "        max_val = max(self.convergence_window)\n",
    "        min_val = min(self.convergence_window)\n",
    "        variation = abs(max_val - min_val)\n",
    "        \n",
    "        # Check if variation is below threshold\n",
    "        if variation <= self.convergence_threshold:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "                \n",
    "    def _convert_parameters(self, x: np.ndarray) -> Dict[str, Any]:\n",
    "        \"\"\"Convert optimization variables to actual parameter values\"\"\"\n",
    "        x = np.array(x).flatten()\n",
    "        param_values = {}\n",
    "        param_names = list(self.parameter_info.keys())\n",
    "        \n",
    "        for i, param_name in enumerate(param_names):\n",
    "            param_info = self.parameter_info[param_name]\n",
    "            \n",
    "            if param_info['type'] == 'continuous':\n",
    "                param_values[param_name] = x[i]\n",
    "            else:  # discrete\n",
    "                idx = int(np.round(np.clip(x[i], 0, len(param_info['values']) - 1)))\n",
    "                param_values[param_name] = param_info['values'][idx]\n",
    "                \n",
    "        return param_values\n",
    "    \n",
    "    def _prepare_model_input(self, param_values: Dict[str, Any]) -> np.ndarray:\n",
    "        \"\"\"Prepare input array for model prediction\"\"\"\n",
    "        # Convert parameter values to numerical array\n",
    "        param_names = list(self.parameter_info.keys())\n",
    "        x_array = []\n",
    "        \n",
    "        for param_name in param_names:\n",
    "            param_info = self.parameter_info[param_name]\n",
    "            value = param_values[param_name]\n",
    "            \n",
    "            if param_info['type'] == 'discrete':\n",
    "                # Find the index of the discrete value\n",
    "                try:\n",
    "                    idx = param_info['values'].index(value)\n",
    "                    x_array.append(idx)\n",
    "                except ValueError:\n",
    "                    # If value not found, use closest\n",
    "                    x_array.append(0)\n",
    "            else:\n",
    "                x_array.append(float(value))\n",
    "                \n",
    "        return np.array(x_array)\n",
    "    \n",
    "    def objective_function(self, x: np.ndarray) -> List[float]:\n",
    "        \"\"\"Calculate objective values for given parameters\"\"\"\n",
    "        param_values = self._convert_parameters(x)\n",
    "        x_model = self._prepare_model_input(param_values)\n",
    "        \n",
    "        objectives = []\n",
    "        \n",
    "        for obj_name in self.objective_targets.keys():\n",
    "            # Scale input\n",
    "            x_scaled = self.scalers_X[obj_name].transform(x_model.reshape(1, -1))\n",
    "            \n",
    "            # Predict\n",
    "            prediction = self.models[obj_name].predict(x_scaled, verbose=0)[0, 0]\n",
    "            \n",
    "            # Inverse transform\n",
    "            actual_value = self.scalers_y[obj_name].inverse_transform(\n",
    "                np.array([[prediction]])\n",
    "            )[0, 0]\n",
    "            \n",
    "            objectives.append(actual_value)\n",
    "            \n",
    "        return objectives\n",
    "    \n",
    "    def calculate_constraint_penalties(self, objectives: List[float]) -> Tuple[List[float], float]:\n",
    "        \"\"\"Calculate constraint penalties for each objective\"\"\"\n",
    "        penalties = []\n",
    "        total_penalty = 0.0\n",
    "        \n",
    "        for i, obj_name in enumerate(self.objective_targets.keys()):\n",
    "            constraint_config = self.objective_constraints[obj_name]\n",
    "            actual_value = objectives[i]\n",
    "            penalty = 0.0\n",
    "            \n",
    "            if constraint_config['has_constraints']:\n",
    "                penalty_weight = constraint_config['penalty_weight']\n",
    "                \n",
    "                # Check minimum constraint\n",
    "                if constraint_config['min_constraint'] is not None:\n",
    "                    min_val = constraint_config['min_constraint']\n",
    "                    if actual_value < min_val:\n",
    "                        violation = min_val - actual_value\n",
    "                        penalty += penalty_weight * (violation / min_val) ** 2\n",
    "                \n",
    "                # Check maximum constraint\n",
    "                if constraint_config['max_constraint'] is not None:\n",
    "                    max_val = constraint_config['max_constraint']\n",
    "                    if actual_value > max_val:\n",
    "                        violation = actual_value - max_val\n",
    "                        penalty += penalty_weight * (violation / max_val) ** 2\n",
    "            \n",
    "            penalties.append(penalty)\n",
    "            total_penalty += penalty\n",
    "            \n",
    "        return penalties, total_penalty\n",
    "    def calculate_weights(self, objectives: List[float]) -> List[float]:\n",
    "        \"\"\"Calculate weights for each objective based on targets\"\"\"\n",
    "        weights = []\n",
    "        \n",
    "        for i, obj_name in enumerate(self.objective_targets.keys()):\n",
    "            obj_config = self.objective_targets[obj_name]\n",
    "            actual_value = objectives[i]\n",
    "            \n",
    "            if obj_config['type'] == 'target':\n",
    "                target_val = obj_config['target_value']\n",
    "                max_val = obj_config['max_value']\n",
    "                weight = 1.0 - min(1.0, abs(actual_value - target_val) / max_val)\n",
    "            else:  # minimize\n",
    "                max_val = obj_config['max_value']\n",
    "                weight = 1.0 - min(1.0, actual_value / max_val)\n",
    "                \n",
    "            weights.append(max(0.0, weight))  # Ensure non-negative weights\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "    def check_constraint_violations(self, objectives: List[float]) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"Check and report constraint violations\"\"\"\n",
    "        violations = {}\n",
    "        \n",
    "        for i, obj_name in enumerate(self.objective_targets.keys()):\n",
    "            constraint_config = self.objective_constraints[obj_name]\n",
    "            actual_value = objectives[i]\n",
    "            \n",
    "            violation_info = {\n",
    "                'has_violation': False,\n",
    "                'min_violation': None,\n",
    "                'max_violation': None,\n",
    "                'violation_amount': 0.0\n",
    "            }\n",
    "            \n",
    "            if constraint_config['has_constraints']:\n",
    "                # Check minimum constraint\n",
    "                if constraint_config['min_constraint'] is not None:\n",
    "                    min_val = constraint_config['min_constraint']\n",
    "                    if actual_value < min_val:\n",
    "                        violation_info['has_violation'] = True\n",
    "                        violation_info['min_violation'] = min_val - actual_value\n",
    "                        violation_info['violation_amount'] += violation_info['min_violation']\n",
    "                \n",
    "                # Check maximum constraint\n",
    "                if constraint_config['max_constraint'] is not None:\n",
    "                    max_val = constraint_config['max_constraint']\n",
    "                    if actual_value > max_val:\n",
    "                        violation_info['has_violation'] = True\n",
    "                        violation_info['max_violation'] = actual_value - max_val\n",
    "                        violation_info['violation_amount'] += violation_info['max_violation']\n",
    "            \n",
    "            violations[obj_name] = violation_info\n",
    "            \n",
    "        return violations\n",
    "    \n",
    "    def combined_objective(self, x: np.ndarray) -> float:\n",
    "        \"\"\"Calculate combined weighted objective with constraint penalties\"\"\"\n",
    "        objectives = self.objective_function(x)\n",
    "        weights = self.calculate_weights(objectives)\n",
    "        \n",
    "        # Calculate constraint penalties\n",
    "        penalties, total_penalty = self.calculate_constraint_penalties(objectives)\n",
    "        \n",
    "        # Normalize and combine objectives\n",
    "        combined_score = 0.0\n",
    "        \n",
    "        for i, obj_name in enumerate(self.objective_targets.keys()):\n",
    "            # Scale the objective\n",
    "            scaled_obj = self.scalers_y[obj_name].transform(\n",
    "                np.array([[objectives[i]]])\n",
    "            )[0, 0]\n",
    "            \n",
    "            combined_score += weights[i] * scaled_obj\n",
    "        \n",
    "        # Add constraint penalties (higher penalty = worse solution)\n",
    "        combined_score += total_penalty\n",
    "            \n",
    "        return combined_score\n",
    "    \n",
    "    def update_velocity(self, velocity: float, position: float, \n",
    "                       personal_best_position: float, global_best_position: float) -> float:\n",
    "        \"\"\"Update particle velocity\"\"\"\n",
    "        inertia_term = self.inertia_weight * velocity\n",
    "        personal_best_term = 2.0 * np.random.rand() * (personal_best_position - position)\n",
    "        global_best_term = 2.0 * np.random.rand() * (global_best_position - position)\n",
    "        return inertia_term + personal_best_term + global_best_term\n",
    "    \n",
    "    def pso_objective(self, x: np.ndarray) -> float:\n",
    "        \"\"\"PSO objective function with tracking and constraint handling\"\"\"\n",
    "        actual_objectives = self.objective_function(x)\n",
    "        combined_result = self.combined_objective(x)\n",
    "        weights = self.calculate_weights(actual_objectives)\n",
    "        \n",
    "        # Calculate constraint penalties and violations\n",
    "        penalties, total_penalty = self.calculate_constraint_penalties(actual_objectives)\n",
    "        violations = self.check_constraint_violations(actual_objectives)\n",
    "        \n",
    "        # Store results\n",
    "        param_values = self._convert_parameters(x)\n",
    "        self.best_solutions_history.append(param_values.copy())\n",
    "        self.actual_value_history.append(actual_objectives.copy())\n",
    "        self.best_values_history.append(combined_result)\n",
    "        self.constraint_penalty_history.append(total_penalty)\n",
    "        self.constraint_violation_history.append(violations)\n",
    "        \n",
    "        # Store individual objective histories\n",
    "        for i, obj_name in enumerate(self.objective_targets.keys()):\n",
    "            scaled_obj = self.scalers_y[obj_name].transform(\n",
    "                np.array([[actual_objectives[i]]])\n",
    "            )[0, 0]\n",
    "            weighted_obj = weights[i] * scaled_obj\n",
    "            self.objective_histories[obj_name].append(weighted_obj)\n",
    "        \n",
    "        # Update global best\n",
    "        if combined_result < self.best_global_value:\n",
    "            self.best_global_position = x.copy()\n",
    "            self.best_global_value = combined_result\n",
    "        \n",
    "        # Check for early termination based on convergence\n",
    "        if self._check_convergence(combined_result):\n",
    "            self.early_terminated = True\n",
    "            self.termination_reason = f\"Early termination: No significant improvement for {self.stagnation_limit} consecutive iterations (threshold: {self.convergence_threshold})\"\n",
    "            print(f\"\\n {self.termination_reason}\")\n",
    "            print(f\"   Current iteration: {len(self.best_values_history)}\")\n",
    "            print(f\"   Convergence window values: {[f'{v:.6f}' for v in self.convergence_window]}\")\n",
    "            print(f\"   Variation in window: {abs(max(self.convergence_window) - min(self.convergence_window)):.6f}\")\n",
    "            \n",
    "        return combined_result\n",
    "    \n",
    "    def run_optimization(self, swarmsize: int = 20, maxiter: int = 3000):\n",
    "        \"\"\"Run the PSO optimization with early termination capability\"\"\"\n",
    "        print(f\"\\n--- RUNNING OPTIMIZATION ---\")\n",
    "        print(f\"Swarm size: {swarmsize}, Max iterations: {maxiter}\")\n",
    "        print(f\"Early termination: Enabled (threshold: {self.convergence_threshold}, stagnation limit: {self.stagnation_limit})\")\n",
    "        \n",
    "        # Prepare bounds for PSO\n",
    "        param_names = list(self.parameter_info.keys())\n",
    "        lower_bounds = [self.bounds[name][0] for name in param_names]\n",
    "        upper_bounds = [self.bounds[name][1] for name in param_names]\n",
    "        \n",
    "        # Initialize PSO variables\n",
    "        self.velocity = np.zeros_like(lower_bounds)\n",
    "        self.best_global_position = np.zeros_like(lower_bounds)\n",
    "        self.best_global_value = np.inf\n",
    "        \n",
    "        # Reset early termination flags\n",
    "        self.early_terminated = False\n",
    "        self.termination_reason = \"\"\n",
    "        self.convergence_window = []\n",
    "        \n",
    "        # Custom PSO implementation with early termination\n",
    "        try:\n",
    "            best_solution, best_value = self._custom_pso_with_early_termination(\n",
    "                lower_bounds, upper_bounds, swarmsize, maxiter\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during PSO optimization: {e}\")\n",
    "            # Fallback to regular PSO if custom implementation fails\n",
    "            print(\"Falling back to standard PSO...\")\n",
    "            best_solution, best_value = pso(\n",
    "                self.pso_objective,\n",
    "                lower_bounds,\n",
    "                upper_bounds,\n",
    "                swarmsize=swarmsize,\n",
    "                maxiter=maxiter\n",
    "            )\n",
    "        \n",
    "        # Print termination information\n",
    "        if self.early_terminated:\n",
    "            print(f\"\\n Optimization terminated early!\")\n",
    "            print(f\"   Reason: {self.termination_reason}\")\n",
    "            print(f\"   Total iterations completed: {len(self.best_values_history)}\")\n",
    "            print(f\"   Iterations saved: {maxiter - len(self.best_values_history)}\")\n",
    "        else:\n",
    "            print(f\"\\n Optimization completed all {maxiter} iterations\")\n",
    "            self.termination_reason = f\"Completed all {maxiter} iterations\"\n",
    "        \n",
    "        return self._convert_parameters(best_solution), best_value\n",
    "\n",
    "    \n",
    "    def _custom_pso_with_early_termination(self, lower_bounds, upper_bounds, swarmsize, maxiter):\n",
    "        \"\"\"\n",
    "        Custom PSO implementation with early termination capability.\n",
    "        This wraps the standard PSO but adds early termination logic.\n",
    "        \"\"\"\n",
    "        iteration_count = [0]  # Use list to allow modification in nested function\n",
    "        pbar = tqdm(total=maxiter, desc=\"Optimization Progress\", ncols=100, unit=\"iter\")\n",
    "        \n",
    "        def early_termination_wrapper(x):\n",
    "            \"\"\"Wrapper function that adds early termination logic\"\"\"\n",
    "            result = self.pso_objective(x)\n",
    "            iteration_count[0] += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Check if we should terminate early\n",
    "            if self.early_terminated:\n",
    "                # Force termination by raising a custom exception\n",
    "                pbar.close()\n",
    "                raise EarlyTerminationException(\"Early termination condition met\")\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        try:\n",
    "            # Run PSO with the wrapper function\n",
    "            best_solution, best_value = pso(\n",
    "                early_termination_wrapper,\n",
    "                lower_bounds,\n",
    "                upper_bounds,\n",
    "                swarmsize=swarmsize,\n",
    "                maxiter=maxiter\n",
    "            )\n",
    "        except EarlyTerminationException:\n",
    "            # Early termination occurred, use the best solution found so far\n",
    "            best_solution = self.best_global_position\n",
    "            best_value = self.best_global_value\n",
    "        \n",
    "        finally:\n",
    "            pbar.close()  # close bar if optimization finishes normally or errors\n",
    "        return best_solution, best_value\n",
    "    \n",
    "    def save_results(self, output_filename: str = None):\n",
    "        \"\"\"Save optimization results to Excel\"\"\"\n",
    "        if output_filename is None:\n",
    "            objectives_str = \"_\".join(self.objective_targets.keys())\n",
    "            output_filename = f'MOPSO_Results_{objectives_str}.xlsx'\n",
    "            \n",
    "        output_path = os.path.join(self.base_path, output_filename)\n",
    "        \n",
    "        # Prepare data for DataFrame\n",
    "        data = []\n",
    "        param_names = list(self.parameter_info.keys())\n",
    "        obj_names = list(self.objective_targets.keys())\n",
    "        \n",
    "        for i in range(len(self.best_solutions_history)):\n",
    "            row = {'Iteration': i + 1}\n",
    "            \n",
    "            # Add parameter values\n",
    "            for param_name in param_names:\n",
    "                row[param_name] = self.best_solutions_history[i][param_name]\n",
    "            \n",
    "            # Add objective values\n",
    "            for j, obj_name in enumerate(obj_names):\n",
    "                row[f'Actual_{obj_name}'] = self.actual_value_history[i][j]\n",
    "                row[f'Normalized_Weighted_{obj_name}'] = self.objective_histories[obj_name][i]\n",
    "                \n",
    "                # Add constraint information\n",
    "                violations = self.constraint_violation_history[i][obj_name]\n",
    "                row[f'{obj_name}_Constraint_Violated'] = violations['has_violation']\n",
    "                if violations['has_violation']:\n",
    "                    row[f'{obj_name}_Violation_Amount'] = violations['violation_amount']\n",
    "                else:\n",
    "                    row[f'{obj_name}_Violation_Amount'] = 0.0\n",
    "            \n",
    "            row['Combined_Objective_Value'] = self.best_values_history[i]\n",
    "            row['Total_Constraint_Penalty'] = self.constraint_penalty_history[i]\n",
    "            row['Is_Feasible'] = self.constraint_penalty_history[i] == 0.0\n",
    "            data.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Add termination information to a separate sheet\n",
    "        termination_info = pd.DataFrame([{\n",
    "            'Termination_Reason': self.termination_reason,\n",
    "            'Early_Terminated': self.early_terminated,\n",
    "            'Total_Iterations': len(self.best_values_history),\n",
    "            'Convergence_Threshold': self.convergence_threshold,\n",
    "            'Stagnation_Limit': self.stagnation_limit,\n",
    "            'Final_Best_Value': self.best_global_value if hasattr(self, 'best_global_value') else 'N/A'\n",
    "        }])\n",
    "        \n",
    "        # Save to Excel with multiple sheets\n",
    "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "            df.to_excel(writer, sheet_name='Optimization_Results', index=False)\n",
    "            termination_info.to_excel(writer, sheet_name='Termination_Info', index=False)\n",
    "        \n",
    "        print(f\"\\n Results saved to: {output_path}\")\n",
    "        print(f\" - Optimization results: 'Optimization_Results' sheet\")\n",
    "        print(f\" - Termination information: 'Termination_Info' sheet\")\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def plot_convergence(self, save_path: str = None):\n",
    "        \"\"\"Plot convergence curve with constraint information and early termination indicator\"\"\"\n",
    "        if save_path is None:\n",
    "            save_path = os.path.join(self.base_path, 'convergence.jpg')\n",
    "            \n",
    "        iterations = range(1, len(self.best_values_history) + 1)\n",
    "        \n",
    "        plt.rcParams['font.family'] = 'Arial'\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        # Plot 1: Convergence curve\n",
    "        ax1.plot(iterations, self.best_values_history,\n",
    "                label='Combined Objective', color='darkblue', linestyle='-',\n",
    "                marker='o', markersize=4, markerfacecolor='#2A7CCC', \n",
    "                markeredgecolor='black', linewidth=2)\n",
    "        \n",
    "        ax1.plot(iterations, self.constraint_penalty_history,\n",
    "                label='Constraint Penalty', color='red', linestyle='--',\n",
    "                marker='s', markersize=4, markerfacecolor='red', \n",
    "                markeredgecolor='black', linewidth=2)\n",
    "        \n",
    "        # Add early termination indicator\n",
    "        if self.early_terminated:\n",
    "            ax1.axvline(x=len(self.best_values_history), color='orange', linestyle=':', \n",
    "                       linewidth=3, label=f'Early Termination (Iter {len(self.best_values_history)})')\n",
    "            ax1.text(len(self.best_values_history), max(self.best_values_history) * 0.8, \n",
    "                    'Early\\nTermination', rotation=90, ha='center', va='bottom',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"orange\", alpha=0.7))\n",
    "        \n",
    "        ax1.set_xlabel('Iteration', fontdict={'fontsize': 12, 'fontname': 'Arial'})\n",
    "        ax1.set_ylabel('Objective Value', fontdict={'fontsize': 12, 'fontname': 'Arial'})\n",
    "        ax1.set_title('MOPSO Convergence with Constraints and Early Termination', fontsize=14, fontweight='bold')\n",
    "        ax1.legend(prop={'family': 'Arial', 'size': 10})\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Feasibility tracking\n",
    "        feasible_points = [1 if penalty == 0.0 else 0 for penalty in self.constraint_penalty_history]\n",
    "        ax2.fill_between(iterations, feasible_points, alpha=0.3, color='green', label='Feasible Region')\n",
    "        ax2.plot(iterations, feasible_points, color='darkgreen', linewidth=2, label='Feasibility')\n",
    "        \n",
    "        # Add early termination indicator to second plot\n",
    "        if self.early_terminated:\n",
    "            ax2.axvline(x=len(self.best_values_history), color='orange', linestyle=':', \n",
    "                       linewidth=3, label=f'Early Termination (Iter {len(self.best_values_history)})')\n",
    "        \n",
    "        ax2.set_xlabel('Iteration', fontdict={'fontsize': 12, 'fontname': 'Arial'})\n",
    "        ax2.set_ylabel('Feasible (1) / Infeasible (0)', fontdict={'fontsize': 12, 'fontname': 'Arial'})\n",
    "        ax2.set_title('Solution Feasibility Over Time', fontsize=14, fontweight='bold')\n",
    "        ax2.legend(prop={'family': 'Arial', 'size': 10})\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_ylim(-0.1, 1.1)\n",
    "        \n",
    "        # Add termination information as text\n",
    "        termination_text = f\"Termination: {self.termination_reason}\"\n",
    "        if len(termination_text) > 60:\n",
    "            termination_text = termination_text[:60] + \"...\"\n",
    "        \n",
    "        plt.figtext(0.02, 0.02, termination_text, fontsize=10, \n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(bottom=0.1)  # Make room for termination text\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\" Convergence plot saved to: {save_path}\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_actual_objective_histories(self, save_path: str = None):\n",
    "        \"\"\"\n",
    "        Plot actual (unscaled, unweighted) value histories for all objectives.\n",
    "        \"\"\"\n",
    "        if save_path is None:\n",
    "            save_path = os.path.join(self.base_path, 'actual_objective_histories.jpg')\n",
    "        \n",
    "        iterations = range(1, len(self.actual_value_history) + 1)\n",
    "        obj_names = list(self.objective_targets.keys())\n",
    "        actual_values = np.array(self.actual_value_history)  # shape: (iterations, num_objs)\n",
    "\n",
    "        plt.rcParams['font.family'] = 'Arial'\n",
    "        fig, axes = plt.subplots(len(obj_names), 1, figsize=(12, 4 * len(obj_names)), sharex=True)\n",
    "\n",
    "        if len(obj_names) == 1:\n",
    "            axes = [axes]  # make iterable for consistency\n",
    "\n",
    "        # Plot each objective history\n",
    "        for i, obj_name in enumerate(obj_names):\n",
    "            axes[i].plot(\n",
    "                iterations, actual_values[:, i],\n",
    "                label=f'Actual {obj_name}', color='blue',\n",
    "                marker='o', markersize=4, linewidth=2\n",
    "            )\n",
    "        \n",
    "            # Early termination marker\n",
    "            if self.early_terminated:\n",
    "                axes[i].axvline(\n",
    "                    x=len(self.best_values_history), color='orange', linestyle=':',\n",
    "                    linewidth=2, label=f'Early Termination (Iter {len(self.best_values_history)})'\n",
    "                )\n",
    "        \n",
    "            axes[i].set_ylabel(f'{obj_name} Value', fontdict={'fontsize': 12, 'fontname': 'Arial'})\n",
    "            axes[i].set_title(f'History of {obj_name}', fontsize=14, fontweight='bold')\n",
    "            axes[i].legend(prop={'family': 'Arial', 'size': 10})\n",
    "            axes[i].grid(False)\n",
    "\n",
    "        axes[-1].set_xlabel('Iteration', fontdict={'fontsize': 12, 'fontname': 'Arial'})\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\" Actual objective histories plot saved to: {save_path}\")\n",
    "        plt.show()\n",
    "    \n",
    "    def print_final_results(self, best_solution: Dict[str, Any], best_value: float):\n",
    "        \"\"\"Print final optimization results with constraint information and early termination details\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FINAL OPTIMIZATION RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Print termination information\n",
    "        print(f\"\\nTermination Information:\")\n",
    "        print(f\"  Status: {'Early Terminated' if self.early_terminated else 'Completed All Iterations'}\")\n",
    "        print(f\"  Reason: {self.termination_reason}\")\n",
    "        print(f\"  Total iterations: {len(self.best_values_history)}\")\n",
    "        if self.early_terminated:\n",
    "            print(f\"  Convergence threshold: {self.convergence_threshold}\")\n",
    "            print(f\"  Stagnation limit: {self.stagnation_limit} iterations\")\n",
    "            if self.convergence_window:\n",
    "                print(f\"  Final convergence window: {[f'{v:.6f}' for v in self.convergence_window]}\")\n",
    "                print(f\"  Window variation: {abs(max(self.convergence_window) - min(self.convergence_window)):.6f}\")\n",
    "        \n",
    "        print(\"\\nBest Parameter Values:\")\n",
    "        for param_name, value in best_solution.items():\n",
    "            print(f\"  {param_name}: {value}\")\n",
    "        \n",
    "        print(f\"\\nBest Combined Objective Value: {best_value:.6f}\")\n",
    "        \n",
    "        # Get final objective values\n",
    "        param_names = list(self.parameter_info.keys())\n",
    "        x_array = []\n",
    "        for param_name in param_names:\n",
    "            param_info = self.parameter_info[param_name]\n",
    "            value = best_solution[param_name]\n",
    "            \n",
    "            if param_info['type'] == 'discrete':\n",
    "                idx = param_info['values'].index(value)\n",
    "                x_array.append(idx)\n",
    "            else:\n",
    "                x_array.append(float(value))\n",
    "        \n",
    "        final_objectives = self.objective_function(np.array(x_array))\n",
    "        final_violations = self.check_constraint_violations(final_objectives)\n",
    "        final_penalties, total_penalty = self.calculate_constraint_penalties(final_objectives)\n",
    "        \n",
    "        print(\"\\nFinal Objective Values:\")\n",
    "        for i, obj_name in enumerate(self.objective_targets.keys()):\n",
    "            print(f\"  {obj_name}: {final_objectives[i]:.4f}\")\n",
    "        \n",
    "        # Print constraint status\n",
    "        print(f\"\\nConstraint Status:\")\n",
    "        print(f\"  Total Penalty: {total_penalty:.6f}\")\n",
    "        print(f\"  Solution is {'FEASIBLE' if total_penalty == 0.0 else 'INFEASIBLE'}\")\n",
    "        \n",
    "        if total_penalty > 0.0:\n",
    "            print(\"\\n  Constraint Violations:\")\n",
    "            for obj_name, violation_info in final_violations.items():\n",
    "                if violation_info['has_violation']:\n",
    "                    constraint_config = self.objective_constraints[obj_name]\n",
    "                    print(f\"    {obj_name}:\")\n",
    "                    \n",
    "                    if violation_info['min_violation'] is not None:\n",
    "                        min_limit = constraint_config['min_constraint']\n",
    "                        actual_val = final_objectives[list(self.objective_targets.keys()).index(obj_name)]\n",
    "                        print(f\"      Minimum violation: {actual_val:.4f} < {min_limit:.4f} (violation: {violation_info['min_violation']:.4f})\")\n",
    "                    \n",
    "                    if violation_info['max_violation'] is not None:\n",
    "                        max_limit = constraint_config['max_constraint']\n",
    "                        actual_val = final_objectives[list(self.objective_targets.keys()).index(obj_name)]\n",
    "                        print(f\"      Maximum violation: {actual_val:.4f} > {max_limit:.4f} (violation: {violation_info['max_violation']:.4f})\")\n",
    "        \n",
    "        # Print constraint summary\n",
    "        print(f\"\\nConstraint Summary:\")\n",
    "        for obj_name in self.objective_targets.keys():\n",
    "            constraint_config = self.objective_constraints[obj_name]\n",
    "            if constraint_config['has_constraints']:\n",
    "                print(f\"  {obj_name}:\")\n",
    "                if constraint_config['min_constraint'] is not None:\n",
    "                    print(f\"    Minimum: >= {constraint_config['min_constraint']}\")\n",
    "                if constraint_config['max_constraint'] is not None:\n",
    "                    print(f\"    Maximum: <= {constraint_config['max_constraint']}\")\n",
    "                print(f\"    Penalty Weight: {constraint_config['penalty_weight']}\")\n",
    "            else:\n",
    "                print(f\"  {obj_name}: No constraints\")\n",
    "        \n",
    "        # Statistics about feasible solutions\n",
    "        feasible_solutions = sum(1 for penalty in self.constraint_penalty_history if penalty == 0.0)\n",
    "        total_solutions = len(self.constraint_penalty_history)\n",
    "        feasibility_rate = (feasible_solutions / total_solutions) * 100\n",
    "        \n",
    "        print(f\"\\nOptimization Statistics:\")\n",
    "        print(f\"  Total iterations: {total_solutions}\")\n",
    "        print(f\"  Feasible solutions: {feasible_solutions} ({feasibility_rate:.1f}%)\")\n",
    "        print(f\"  Infeasible solutions: {total_solutions - feasible_solutions} ({100-feasibility_rate:.1f}%)\")\n",
    "        \n",
    "        # Early termination efficiency statistics\n",
    "        if self.early_terminated:\n",
    "            max_possible_iter = 3000  # You can make this a parameter\n",
    "            efficiency_gain = ((max_possible_iter - total_solutions) / max_possible_iter) * 100\n",
    "            print(f\"  Early termination efficiency: {efficiency_gain:.1f}% iterations saved\")\n",
    "        \n",
    "        if feasible_solutions > 0:\n",
    "            print(f\"\\n Found {feasible_solutions} feasible solution(s) during optimization\")\n",
    "        else:\n",
    "            print(f\"\\n  No feasible solutions found. Consider:\")\n",
    "            print(f\"     - Relaxing constraints\")\n",
    "            print(f\"     - Increasing penalty weights\")\n",
    "            print(f\"     - Expanding parameter bounds\")\n",
    "            print(f\"     - Increasing number of iterations\")\n",
    "            if self.early_terminated:\n",
    "                print(f\"     - Adjusting convergence threshold (current: {self.convergence_threshold})\")\n",
    "                print(f\"     - Increasing stagnation limit (current: {self.stagnation_limit})\")\n",
    "\n",
    "\n",
    "# Custom exception for early termination\n",
    "class EarlyTerminationException(Exception):\n",
    "    \"\"\"Custom exception to handle early termination in PSO optimization\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Create optimizer instance\n",
    "    optimizer = GeneralizedMOPSO()\n",
    "    \n",
    "    try:\n",
    "        # Setup environment\n",
    "        optimizer.setup_environment()\n",
    "        \n",
    "        # Get optimization parameters\n",
    "        print(\"\\n--- OPTIMIZATION PARAMETERS ---\")\n",
    "        swarmsize = int(input(\"Enter swarm size (default 20): \") or \"20\")\n",
    "        maxiter = int(input(\"Enter maximum iterations (default 3000): \") or \"3000\")\n",
    "        \n",
    "        # Get early termination parameters\n",
    "        print(\"\\n--- EARLY TERMINATION PARAMETERS ---\")\n",
    "        use_default_termination = input(\"Use default early termination settings? (y/n, default: y): \").strip().lower()\n",
    "        \n",
    "        if use_default_termination != 'n':\n",
    "            print(\"Using default settings:\")\n",
    "            print(\"  - Convergence threshold: 10e-6\")\n",
    "            print(\"  - Stagnation limit: 50 iterations\")\n",
    "        else:\n",
    "            custom_threshold = input(\"Enter convergence threshold (default: 10e-6): \").strip()\n",
    "            if custom_threshold:\n",
    "                optimizer.convergence_threshold = float(custom_threshold)\n",
    "            \n",
    "            custom_stagnation = input(\"Enter stagnation limit in iterations (default: 50): \").strip()\n",
    "            if custom_stagnation:\n",
    "                optimizer.stagnation_limit = int(custom_stagnation)\n",
    "        \n",
    "        print(f\"\\nFinal early termination settings:\")\n",
    "        print(f\"  - Convergence threshold: {optimizer.convergence_threshold}\")\n",
    "        print(f\"  - Stagnation limit: {optimizer.stagnation_limit} iterations\")\n",
    "        print(f\"  - Termination occurs when predicted values show no significant\")\n",
    "        print(f\"    variation (< {optimizer.convergence_threshold}) for {optimizer.stagnation_limit} consecutive iterations\")\n",
    "        \n",
    "        # Run optimization\n",
    "        best_solution, best_value = optimizer.run_optimization(swarmsize, maxiter)\n",
    "        \n",
    "        # Save results\n",
    "        optimizer.save_results()\n",
    "        \n",
    "        # Plot convergence\n",
    "        optimizer.plot_convergence()\n",
    "        optimizer.plot_actual_objective_histories()\n",
    "        \n",
    "        # Print final results\n",
    "        optimizer.print_final_results(best_solution, best_value)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error during optimization: {e}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
